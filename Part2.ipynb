{"metadata":{"colab":{"name":"Welcome To Colab","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\"  )\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:09.306102Z","iopub.execute_input":"2024-05-25T13:12:09.306377Z","iopub.status.idle":"2024-05-25T13:12:12.827181Z","shell.execute_reply.started":"2024-05-25T13:12:09.306352Z","shell.execute_reply":"2024-05-25T13:12:12.826349Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/409 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd29ccdc28774d858d615014d87d7d54"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 14.4M/14.4M [00:00<00:00, 26.7MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72a759f5061c4f9a8453728e0150bbcc"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n        num_rows: 4838\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:12.828183Z","iopub.execute_input":"2024-05-25T13:12:12.829744Z","iopub.status.idle":"2024-05-25T13:12:18.792437Z","shell.execute_reply.started":"2024-05-25T13:12:12.829716Z","shell.execute_reply":"2024-05-25T13:12:18.791632Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd3c18ae6504173b421415ac6bc079c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5366fdb7c624ad181b670de2f5c2131"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff14b2f10a37417d8a447cb580a0c2c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3389dd46c5bb45c28c2c91632c91f305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"978b3d4048504a709f86460fb4f9c210"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ndef tokenize_function(examples):\n    return tokenizer(examples['chunk'],padding='max_length', truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:18.794531Z","iopub.execute_input":"2024-05-25T13:12:18.794980Z","iopub.status.idle":"2024-05-25T13:12:33.926770Z","shell.execute_reply.started":"2024-05-25T13:12:18.794954Z","shell.execute_reply":"2024-05-25T13:12:33.925819Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4838 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184bffc6cd9a4a48ab99b2254ab13062"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:33.927824Z","iopub.execute_input":"2024-05-25T13:12:33.928083Z","iopub.status.idle":"2024-05-25T13:12:33.933857Z","shell.execute_reply.started":"2024-05-25T13:12:33.928061Z","shell.execute_reply":"2024-05-25T13:12:33.932990Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references', 'input_ids', 'attention_mask'],\n        num_rows: 4838\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel , Trainer , TrainingArguments\nfrom transformers import DataCollatorForLanguageModeling\nimport torch\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)\n\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'\n\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:44.717884Z","iopub.execute_input":"2024-05-25T13:12:44.718668Z","iopub.status.idle":"2024-05-25T13:12:48.620184Z","shell.execute_reply.started":"2024-05-25T13:12:44.718633Z","shell.execute_reply":"2024-05-25T13:12:48.619136Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edd668148bfa4e558e659056d289e0f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0e9a66c87b4ca08cc0d25df8156076"}},"metadata":{}}]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=3,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    data_collator=data_collator,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:12:48.623858Z","iopub.execute_input":"2024-05-25T13:12:48.624352Z","iopub.status.idle":"2024-05-25T14:02:05.745252Z","shell.execute_reply.started":"2024-05-25T13:12:48.624316Z","shell.execute_reply":"2024-05-25T14:02:05.744344Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240525_131254-jo7ozaxn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dr2/huggingface/runs/jo7ozaxn' target=\"_blank\">generous-pine-17</a></strong> to <a href='https://wandb.ai/dr2/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dr2/huggingface' target=\"_blank\">https://wandb.ai/dr2/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dr2/huggingface/runs/jo7ozaxn' target=\"_blank\">https://wandb.ai/dr2/huggingface/runs/jo7ozaxn</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2421' max='2421' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2421/2421 48:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.030300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.659100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.380000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.234300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2421, training_loss=3.5109219903642606, metrics={'train_runtime': 2955.7999, 'train_samples_per_second': 4.91, 'train_steps_per_second': 0.819, 'total_flos': 7584785104896000.0, 'train_loss': 3.5109219903642606, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('./fine_tuned_gpt2')\ntokenizer.save_pretrained('./fine_tuned_gpt2')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:02:05.746474Z","iopub.execute_input":"2024-05-25T14:02:05.746830Z","iopub.status.idle":"2024-05-25T14:02:06.845368Z","shell.execute_reply.started":"2024-05-25T14:02:05.746799Z","shell.execute_reply":"2024-05-25T14:02:06.843778Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_gpt2/tokenizer_config.json',\n './fine_tuned_gpt2/special_tokens_map.json',\n './fine_tuned_gpt2/vocab.json',\n './fine_tuned_gpt2/merges.txt',\n './fine_tuned_gpt2/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\nfine_tuned_model = GPT2LMHeadModel.from_pretrained('./fine_tuned_gpt2')\nfine_tuned_tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_gpt2')\n\nprompt = \"how does the performance of llama 2 compare to other local LLMs?\"\n\ninput_ids = fine_tuned_tokenizer.encode(prompt, return_tensors='pt')\n\noutput = fine_tuned_model.generate(\n    input_ids, \n    max_length=100,\n    num_return_sequences=1,\n    temperature=1.0,\n    top_k=50,\n    top_p=0.95,\n    do_sample=True\n)\n\ngenerated_text = fine_tuned_tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:09:22.502208Z","iopub.execute_input":"2024-05-25T14:09:22.502575Z","iopub.status.idle":"2024-05-25T14:09:26.004854Z","shell.execute_reply.started":"2024-05-25T14:09:22.502547Z","shell.execute_reply":"2024-05-25T14:09:26.003870Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"how does the performance of llama 2 compare to other local LLMs? In each case, the performance of llama 2 was measured using the\nsame\nstacked LLMs (using a non-linearity with respect to the weights of\nthe current test model).\nAs shown in Fig. 1, the performance of llama 2 is quite different. On the\ntest set, llama 2 is faster than the current LLMs and the performance of llama 3\nis slightly worse\n","output_type":"stream"}]}]}